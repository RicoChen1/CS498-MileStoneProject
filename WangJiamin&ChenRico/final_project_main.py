# -*- coding: utf-8 -*-
"""Final Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XKA4-z3cuapmo94kViOl6ewdc4d8X-AJ

# Purpose of the First Part of Training: Handle the generation of medical images using GANs

## Training Objective
To train a generator that, given random noise input, is capable of producing synthetic images resembling real medical MRI slices.

## Data Acquisition
 - Downloaded the BraTS2020 Brain Tumor MRI Dataset (FLAIR modality) from Kaggle.
 - Purpose: To obtain authentic medical imaging data as foundational material for model development.

## Data Preprocessing
 - Converted each 3D MRI volume (240 x 240 x 155) into a large number of 2D slices through random sampling.
 - To simplify the 3D data structure into 2D representations, enabling more efficient and accelerated model training.

## Building the Gan Model

## Training Gan
 - Trained the Generator to generate fake MRI slices.
 - Trained the Discriminator to distinguish between real and fake slices.
 - Through adversarial training, the Generator ultimated learns to "fake realism".

## Output Results
 - Monitored the Generator's outputs during training to assess their visual realism.
 - To evaluate the success of training based on the Generator's ability to produce images that are indistinguishable from real MRI slices by the Discriminator.

# Install Kaggle API and download dataset
"""

# install Kaggle API
!pip install kaggle

# Upload kaggle.json (API key)
from google.colab import files
files.upload()

# Set up Kaggle authentication
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# down BraTS2020 Dataset
!kaggle datasets download -d awsaf49/brats20-dataset-training-validation

# Unzip to the current directory
#!unzip brats20-dataset-training-validation.zip -d brats2020_data
!unzip -o brats20-dataset-training-validation.zip -d brats2020_data

"""# Import Libraries"""

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from sklearn.model_selection import train_test_split
import nibabel as nib
import matplotlib.pyplot as plt
from glob import glob
import random
import keras.backend as K
from keras.callbacks import CSVLogger
from tensorflow.keras.utils import plot_model

"""# Data Inspection"""

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)
random.seed(42)

# Define data directory
data_dir = "/content/brats2020_data/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData"

# train_dir = os.path.join(data_dir, "BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData")

print(os.listdir(data_dir)) # List patient folders inside data_dir

# Choose one patient's directory
patient_dir = os.path.join(data_dir, 'BraTS20_Training_011')
flair_path = os.path.join(patient_dir, 'BraTS20_Training_011_flair.nii')

# Load the FLAIR MRI image
flair_img = nib.load(flair_path).get_fdata()
print(flair_img.shape)  # should be 240 x 240 x 155

"""# Preprocessing: Convert 3D MRI data into a 2D slice training set"""

# Extract slices from FLAIR images
def extract_slices(image, num_slices=100):
    """
    Extract random 2D slices from 3D MRI data for GAN training.
    """
    slices = []
    total_slices = image.shape[2]
    indices = np.random.choice(total_slices, num_slices, replace=False)

    for idx in indices:
        slice_img = image[:, :, idx]
        # Normalize to [0,1]
        slice_img = (slice_img - np.min(slice_img)) / (np.max(slice_img) - np.min(slice_img) + 1e-5)
        slices.append(slice_img)

    return np.array(slices)

# Extract 100 2D slices from a single patient
slices = extract_slices(flair_img, num_slices=100)
print(slices.shape)

# visualize one of them
plt.imshow(slices[0], cmap='gray')
plt.title('FLAIR MRI Slice')
plt.axis('off')
plt.show()

# Randomly select 5 slices for visualization
n_samples = 5
indices = np.random.choice(slices.shape[0], n_samples, replace=False)

fig, axs = plt.subplots(1, n_samples, figsize=(20, 5))

for i, idx in enumerate(indices):
    axs[i].imshow(slices[idx], cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(f'Slice #{idx}')

plt.tight_layout()
plt.show()

"""# Build a TensorFlow-based GAN model

## Generator
"""

def build_generator(latent_dim):
    model = tf.keras.Sequential([
        layers.Dense(60 * 60 * 128, input_dim=latent_dim),
        layers.Reshape((60, 60, 128)),
        layers.Conv2DTranspose(64, 4, strides=2, padding='same'),  # 120x120
        layers.BatchNormalization(),
        layers.ReLU(),
        layers.Conv2DTranspose(32, 4, strides=2, padding='same'),  # 240x240
        layers.BatchNormalization(),
        layers.ReLU(),
        layers.Conv2D(1, kernel_size=3, padding='same', activation='tanh')
    ], name="Generator")
    return model

"""## Discriminator"""

def build_discriminator():
    model = tf.keras.Sequential([
        layers.Conv2D(32, 4, strides=2, padding='same', input_shape=(240, 240, 1)),
        layers.LeakyReLU(0.2),
        layers.Conv2D(64, 4, strides=2, padding='same'),
        layers.LeakyReLU(0.2),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ], name="Discriminator")
    return model

"""# GAN training function design"""

class GAN(tf.keras.Model):
    def __init__(self, generator, discriminator, latent_dim):
        super(GAN, self).__init__()
        self.generator = generator
        self.discriminator = discriminator
        self.latent_dim = latent_dim

    def compile(self, g_optimizer, d_optimizer, loss_fn):
        super(GAN, self).compile()
        self.g_optimizer = g_optimizer
        self.d_optimizer = d_optimizer
        self.loss_fn = loss_fn

    def train_step(self, real_images):
        batch_size = tf.shape(real_images)[0]
        real_labels = tf.ones((batch_size, 1))
        fake_labels = tf.zeros((batch_size, 1))

        # Train Discriminator
        with tf.GradientTape() as tape:
            z = tf.random.normal((batch_size, self.latent_dim))
            fake_images = self.generator(z)
            real_preds = self.discriminator(real_images)
            fake_preds = self.discriminator(fake_images)
            d_loss_real = self.loss_fn(real_labels, real_preds)
            d_loss_fake = self.loss_fn(fake_labels, fake_preds)
            d_loss = (d_loss_real + d_loss_fake) / 2

        grads = tape.gradient(d_loss, self.discriminator.trainable_variables)
        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))

        # Train Generator
        with tf.GradientTape() as tape:
            z = tf.random.normal((batch_size, self.latent_dim))
            fake_images = self.generator(z)
            fake_preds = self.discriminator(fake_images)
            g_loss = self.loss_fn(real_labels, fake_preds)

        grads = tape.gradient(g_loss, self.generator.trainable_variables)
        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))

        return {"d_loss": d_loss, "g_loss": g_loss}

"""# Configure and start training"""

# Process slices into TensorFlow format
slices = slices[..., np.newaxis]  # Expand to include a channel dimension
slices = (slices - 0.5) / 0.5  # Normalizeåˆ° [-1, 1]

# Create tf.data.Dataset
dataset = tf.data.Dataset.from_tensor_slices(slices).shuffle(buffer_size=1000).batch(32)

# Build models
latent_dim = 100
generator = build_generator(latent_dim)
discriminator = build_discriminator()

# Compile GAN
gan = GAN(generator, discriminator, latent_dim)
gan.compile(
    g_optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
    d_optimizer=optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=False)
)

# Train GAN
gan.fit(dataset, epochs=50)

"""# Purpose of the Second Part of Training
Having completed the training of my GAN model, the next key steps are:
- Use the trained Generator to generate images.
- Plot and visually inspect the generated images.
- Evaluate whether the GAN training was successful.

# Generate images and visualize them

## Step 1: Use the trained Generator to generate a batch of images
"""

n_samples = 5  # Generate 5 images
latent_dim = 100  # Keep consistent with the training setting

# Randomly generate latent vectors
random_latent_vectors = tf.random.normal(shape=(n_samples, latent_dim))

# Generate images using the trained Generator
generated_images = generator(random_latent_vectors)

"""## Step 2: Denormalization (convert from [-1, 1] back to [0, 1] for better visualization)"""

generated_images = (generated_images + 1) / 2.0

"""## Step 3: Visualize the generated images"""

fig, axs = plt.subplots(1, n_samples, figsize=(20, 5))

for i in range(n_samples):
    axs[i].imshow(generated_images[i, :, :, 0], cmap='gray')
    axs[i].axis('off')
    axs[i].set_title(f'Generated #{i+1}')

plt.tight_layout()
plt.show()

"""Following the initial GAN training, the generated images show early signs of brain-like structures, but remain blurry and unstable.

Texture details are disorganized with visible checkerboard artifacts, and contrast is uneven across regions. Some mode collapse is observed, but not severe.

No clear medical structures such as brain chambers or tumors are identifiable, indicating that further training or model refinement is needed.

Overall, the model has started to form MRI slice shapes, but image quality is poor with high noise levels, and the outputs do not yet meet the standards for medical imaging applications.

# Purpose of the Third Part of Training: Teach the GAN to automatically segment tumors

## Prerequisite:
Train an unconditional GAN that can generate MRI images from random noise.

## Goal: upgrade to a conditional GAN (Pix2Pix style) to enable MRI segmentation tasks:
- Input: MRI image
- Output: Tumor segmentation mask

## Steps:
- Extract (MRI slice, Mask slice) pairs as input pairs
  - No longer extract only MRI images; corresponding segmentation masks must be extracted simultaneously.
- Modify the Generator architecture
  - Input an MRI image and output the corresponding mask (instead of generating from random noise).
- Modify the Discriminator architecture
  - Input (MRI, Mask) pairs and determine whether they form a "real" combination.
- Modify the Loss function
  - Optimize with a combination of GAN loss + BCE loss to ensure that the generated masks are realistic and accurate.
- Modify the Training Logic
  - No longer generate from random noise, but instead generate masks based on the input MRI images.

## 1. Extracting MRI+Mask

I have already extracted the FLAIR images,

now I need to additionally extract the corresponding masks (typically with filenames containing seg.nii).
"""

# Extract (MRI, Mask) pairs
def extract_mri_mask_pairs(image, mask, num_slices=100):
    """
    Randomly extract MRI slices and their corresponding masks for Pix2Pix training.
    """
    mri_slices = []
    mask_slices = []
    total_slices = image.shape[2]
    indices = np.random.choice(total_slices, num_slices, replace=False)

    for idx in indices:
        mri_slice = image[:, :, idx]
        mask_slice = mask[:, :, idx]

        # Normalize MRI slice to [0, 1]
        mri_slice = (mri_slice - np.min(mri_slice)) / (np.max(mri_slice) - np.min(mri_slice) + 1e-5)
        # Normalize mask to binary (0 or 1)
        mask_slice = (mask_slice > 0).astype(np.float32)

        mri_slices.append(mri_slice)
        mask_slices.append(mask_slice)

    return np.array(mri_slices), np.array(mask_slices)

# Loading mask
mask_path = os.path.join(patient_dir, 'BraTS20_Training_011_seg.nii')
mask_img = nib.load(mask_path).get_fdata()

# Extracting MRI-mask slices
mri_slices, mask_slices = extract_mri_mask_pairs(flair_img, mask_img, num_slices=100)

print(mri_slices.shape)  # (100, 240, 240)
print(mask_slices.shape) # (100, 240, 240)

print(flair_img.shape, mask_img.shape)

# Preprocess Tensor
mri_slices = mri_slices[..., np.newaxis] # Add channel dim
mask_slices = mask_slices[..., np.newaxis]

# Normalize MRI to [-1, 1]
mri_slices = (mri_slices - 0.5) / 0.5

# Create Dataset
dataset = tf.data.Dataset.from_tensor_slices((mri_slices, mask_slices)).shuffle(1000).batch(16)

"""## 2. Generator [Upgraded to Pix2Pix Version]
Define a simple U-Net style generator that upsamples an MRI slice into its predicted segmentation mask.
"""

def build_generator_pix2pix():
    """
    Define the generator model using U-Net like structure for Pix2Pix.
    """
    inputs = layers.Input(shape=(240, 240, 1))

    down1 = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)
    down1 = layers.LeakyReLU()(down1)

    down2 = layers.Conv2D(128, 4, strides=2, padding='same')(down1)
    down2 = layers.LeakyReLU()(down2)

    up1 = layers.Conv2DTranspose(64, 4, strides=2, padding='same')(down2)
    up1 = layers.ReLU()(up1)

    up2 = layers.Conv2DTranspose(32, 4, strides=2, padding='same')(up1)
    up2 = layers.ReLU()(up2)

    outputs = layers.Conv2D(1, 3, padding='same', activation='sigmoid')(up2)

    return tf.keras.Model(inputs, outputs, name="Generator_Pix2Pix")

"""## Discriminator [PatchGAN Style]
Build a PatchGAN Discriminator that evaluates if (MRI, mask) pairs are real or fake, focusing on local patches rather than the entire image.
"""

def build_discriminator_pix2pix():
    """
    Define the discriminator model using PatchGAN style.
    """
    input_mri = layers.Input(shape=(240, 240, 1))
    input_mask = layers.Input(shape=(240, 240, 1))
    combined = layers.Concatenate()([input_mri, input_mask])

    x = layers.Conv2D(64, 4, strides=2, padding='same')(combined)
    x = layers.LeakyReLU()(x)

    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)
    x = layers.LeakyReLU()(x)

    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)
    x = layers.LeakyReLU()(x)

    x = layers.Conv2D(1, 4, padding='same')(x)  # Score map

    return tf.keras.Model([input_mri, input_mask], x, name="Discriminator_Pix2Pix")

"""## 3. Loss Function (Combining GAN Loss and BCE Segmentation Loss)
Define generator loss (encourage good segmentation) and discriminator loss (encourage correct real/fake classification).
"""

# Define Binary Crossentropy loss
bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(disc_generated_output, gen_output, target):
    """
    Generator loss = GAN loss + segmentation (BCE) loss.
    """
    gan_loss = bce_loss_fn(tf.ones_like(disc_generated_output), disc_generated_output)
    seg_loss = tf.keras.losses.BinaryCrossentropy()(target, gen_output)
    total_gen_loss = gan_loss + seg_loss
    return total_gen_loss

def discriminator_loss(disc_real_output, disc_generated_output):
    """
    Discriminator loss = real loss + fake loss.
    """
    real_loss = bce_loss_fn(tf.ones_like(disc_real_output), disc_real_output)
    fake_loss = bce_loss_fn(tf.zeros_like(disc_generated_output), disc_generated_output)
    total_disc_loss = (real_loss + fake_loss) * 0.5
    return total_disc_loss

"""## 4. Training Logic (Pix2Pix Version)
- Create the GAN components and set Adam optimizers with recommended hyperparameters for stable training.
- Train the generator and discriminator for one mini-batch using adversarial and segmentation losses.
"""

# Initialize generator and discriminator
generator = build_generator_pix2pix()
discriminator = build_discriminator_pix2pix()

# Define optimizers
g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
d_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

@tf.function
def train_step(input_mri, target_mask):
    """
    Perform one training step: update generator and discriminator.
    """
    with tf.GradientTape(persistent=True) as tape:
        # Generate prediction
        gen_output = generator(input_mri, training=True)

        # Discriminator evaluates real and generated pairs
        disc_real_output = discriminator([input_mri, target_mask], training=True)
        disc_generated_output = discriminator([input_mri, gen_output], training=True)

        # Compute losses
        gen_loss = generator_loss(disc_generated_output, gen_output, target_mask)
        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)

    # Apply gradients
    generator_gradients = tape.gradient(gen_loss, generator.trainable_variables)
    discriminator_gradients = tape.gradient(disc_loss, discriminator.trainable_variables)

    g_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))
    d_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))

    return gen_loss, disc_loss

# Start training
EPOCHS = 50

for epoch in range(EPOCHS):
    print(f"Epoch {epoch+1}/{EPOCHS}")
    for mri_batch, mask_batch in dataset:
        g_loss, d_loss = train_step(mri_batch, mask_batch)

    print(f"Generator Loss: {g_loss.numpy():.4f} - Discriminator Loss: {d_loss.numpy():.4f}")

"""## 5. Generate and visualize prediction results"""

# Generate and visualize predictions
test_mri = mri_slices[:5] # Select 5 test samples

# Predict masks
predicted_mask = generator.predict(test_mri)

# Plot inputs, ground truths, and predictions
fig, axs = plt.subplots(3, 5, figsize=(20, 8))

for i in range(5):
    axs[0, i].imshow((test_mri[i, :, :, 0] * 0.5 + 0.5), cmap='gray')  # input MRI
    axs[0, i].set_title('Input MRI')
    axs[0, i].axis('off')

    axs[1, i].imshow(mask_slices[i, :, :, 0], cmap='gray')  # real Mask
    axs[1, i].set_title('Ground Truth Mask')
    axs[1, i].axis('off')

    axs[2, i].imshow(predicted_mask[i, :, :, 0], cmap='gray')  # predict result
    axs[2, i].set_title('Predicted Mask')
    axs[2, i].axis('off')

plt.tight_layout()
plt.show()

"""We can see that, the presented results demonstrate the Pix2Pix model's ability to predict tumor segmentation masks from MRI input slices.

Overall, the model successfully identifies the tumor regions, particularly in cases with larger lesions. The predicted masks generally align with the ground truth masks, although the boundaries appear somewhat blurred and slightly less precise.

For smaller tumors, the model's performance is less accurate, showing partial or missing segmentations.

No significant false positives were observed. (How to judge: Most of the bright areas of Predicted Masks are basically consistent with the location of the Ground Truth Mask, that is, there is no obvious phenomenon of "it is obviously not a tumor, but a piece of it has been generated.")

Further improvement in boundary refinement and small tumor detection could be achieved through model architecture enhancements or loss function optimization.

# Purpose of the Further Part of Training: Perform automatic evaluation of the Dice Coefficient and IoU Score upon completion of training

Are there formal, quantitative evaluation methods?

- Dice Coefficient (F1 Score for segmentation)
  - Dice = (2TP) / (2TP+FP+FN)
  - Measures the overlap between the predicted mask and the ground truth mask; the closer to 1, the better.


- IoU (Intersection over Union)
  - IoU = (TP) / (TP + FP + FN)
  - Measures the ratio of the intersection area to the union area between the predicted and ground truth masks.

Objective: Automatically compute and output evaluation metrics (Dice and IoU).

## Step 1: Supplementary evaluation function
"""

def dice_coefficient(y_true, y_pred, smooth=1e-6):
    """
    Dice coefficient: measure of overlap between true and predicted masks.
    """
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

def iou_score(y_true, y_pred, smooth=1e-6):
    """
    Intersection over Union (IoU): overlap ratio between true and predicted masks.
    """
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection
    return (intersection + smooth) / (union + smooth)

"""## Step 2: Predict and evaluate after training"""

# ==========================
# Evaluation after training
# ==========================

# Take pictures for testing
test_mri = mri_slices[:10]  # 10 pictures
test_mask = mask_slices[:10]

# Generate a predicted mask
predicted_mask = generator.predict(test_mri)

# Because the prediction output is probability (0 to 1), you can directly threshold it and turn it into 0/1 splitting here.
predicted_mask_bin = (predicted_mask > 0.5).astype(np.float32)

# Calculate Dice and IoU
dice = dice_coefficient(test_mask, predicted_mask_bin)
iou = iou_score(test_mask, predicted_mask_bin)

print(f"Dice Coefficient on test set: {dice.numpy():.4f}")
print(f"IoU Score on test set: {iou.numpy():.4f}")

"""The Pix2Pix model achieved a Dice Coefficient of 0.6990 and an IoU Score of 0.5373 on the test set.

Dice Coefficient: 0.6990 - The predicted segmentation mask overlaps with the ground truth mask by 69.90%.

IoU Score: 0.5373 - The intersection-over-union between the predicted and ground truth masks reaches 53.73%.

Dice Coefficient is nearly 0.7, which suggest that the model has effectively captured the location and morphology of tumor regions, demonstrating satisfactory segmentation performance.

IoU Score is 0.54, which means the model meets the basic effectiveness criteria for medical image segmentation. It still falls short of the performance reported in the paper references, where IoU scores often exceed 0.7.

In sum, these results indicate that the model has successfully learned to locate and segment tumor regions from MRI slices. While the current performance is effective for basic segmentation tasks, further improvements in boundary refinement and small tumor detection could enhance the results. Future work could include optimizing the loss functions for better accuracy.

# Purpose of the Further Part II of Training: Vanilla GAN vs DCGAN in automatically segment tumors

- Vanilla GAN
  - Vanilla GAN is the original form of Generative Adversarial Networks proposed by Ian Goodfellow in 2014.
  - The generator tries to create realistic fake data, while the discriminator tries to distinguish real data from fake data.
  - Training uses a minimax loss function with no architectural improvements.

- DCGANï¼ˆDeep Convolutional GANï¼‰
  - DCGAN is an improved version of GAN that uses CNNs instead of fully connected layers.
  - Use of strided convolutions in the discriminator (for downsampling).
  - Use of fractionally strided convolutions (transposed convolutions) in the generator (for upsampling).
  - No fully connected layers after initial dense layers.
  - Use of Batch Normalization and ReLU/LeakyReLU activations to stabilize training.

## Vanilla GAN for Brain Tumor Segmentation
"""

# Rebuild the dataset using only the masks without using the MRI images
dataset = tf.data.Dataset.from_tensor_slices(mask_slices).shuffle(1000).batch(16)

"""### Step 1: Build Vanilla GAN (simple fully-connected layers)"""

# Vanilla GAN Generator
def build_vanilla_generator(latent_dim):
    model = tf.keras.Sequential([
        layers.Dense(128, activation='relu', input_dim=latent_dim),
        layers.Dense(240 * 240, activation='sigmoid'),
        layers.Reshape((240, 240, 1))
    ], name="Vanilla_Generator")
    return model

# Vanilla GAN Discriminator
def build_vanilla_discriminator():
    model = tf.keras.Sequential([
        layers.Flatten(input_shape=(240, 240, 1)),
        layers.Dense(128, activation='relu'),
        layers.Dense(1, activation='sigmoid')
    ], name="Vanilla_Discriminator")
    return model

"""### Step 2: Training Procedure for Vanilla GAN"""

# Setup
latent_dim_vanilla = 100
vanilla_generator = build_vanilla_generator(latent_dim_vanilla)
vanilla_discriminator = build_vanilla_discriminator()

g_optimizer_vanilla = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
d_optimizer_vanilla = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)

@tf.function
def train_step_vanilla(real_masks):
    batch_size = tf.shape(real_masks)[0]
    real_labels = tf.ones((batch_size, 1))
    fake_labels = tf.zeros((batch_size, 1))

    # Train Discriminator
    with tf.GradientTape() as tape:
        noise = tf.random.normal((batch_size, latent_dim_vanilla))
        generated_masks = vanilla_generator(noise, training=True)

        real_output = vanilla_discriminator(real_masks, training=True)
        fake_output = vanilla_discriminator(generated_masks, training=True)

        d_loss_real = cross_entropy(real_labels, real_output)
        d_loss_fake = cross_entropy(fake_labels, fake_output)
        d_loss = (d_loss_real + d_loss_fake) / 2

    gradients_of_discriminator = tape.gradient(d_loss, vanilla_discriminator.trainable_variables)
    d_optimizer_vanilla.apply_gradients(zip(gradients_of_discriminator, vanilla_discriminator.trainable_variables))

    # Train Generator
    with tf.GradientTape() as tape:
        noise = tf.random.normal((batch_size, latent_dim_vanilla))
        generated_masks = vanilla_generator(noise, training=True)
        fake_output = vanilla_discriminator(generated_masks, training=True)

        g_loss = cross_entropy(real_labels, fake_output)

    gradients_of_generator = tape.gradient(g_loss, vanilla_generator.trainable_variables)
    g_optimizer_vanilla.apply_gradients(zip(gradients_of_generator, vanilla_generator.trainable_variables))

    return d_loss, g_loss

"""### Step 3: Training Vanilla GAN"""

EPOCHS_VANILLA = 50

for epoch in range(EPOCHS_VANILLA):
    print(f"Vanilla GAN Epoch {epoch+1}/{EPOCHS_VANILLA}")
    for real_masks in dataset:
        d_loss, g_loss = train_step_vanilla(real_masks)

    print(f"Discriminator Loss: {d_loss.numpy():.4f}, Generator Loss: {g_loss.numpy():.4f}")

"""### Step 4: Generate and visualize the results of the Vanilla GAN"""

# Generate new predicted Mask
n_generate = 5
random_latent_vectors = tf.random.normal(shape=(n_generate, latent_dim_vanilla))
generated_masks_vanilla = vanilla_generator(random_latent_vectors)

# Visualization
fig, axs = plt.subplots(1, n_generate, figsize=(20, 5))

for i in range(n_generate):
    axs[i].imshow(generated_masks_vanilla[i, :, :, 0], cmap='gray', vmin=0, vmax=1)
    axs[i].axis('off')
    axs[i].set_title(f'Generated Mask #{i+1}')

plt.tight_layout()
plt.show()

"""Obviously, the result is very noisy.

### Evaluation (Dice / IoU)
"""

# Select real masks for evaluation
test_mask = mask_slices[:n_generate]

# Since the generated masks are float values (0-1), binarize them
generated_masks_bin = (generated_masks_vanilla.numpy() > 0.5).astype(np.float32)

# Calculate Dice and IoU
dice_vanilla = dice_coefficient(test_mask, generated_masks_bin)
iou_vanilla = iou_score(test_mask, generated_masks_bin)

print(f"Vanilla GAN Dice Coefficient: {dice_vanilla.numpy():.4f}")
print(f"Vanilla GAN IoU Score: {iou_vanilla.numpy():.4f}")

"""Very low Dice Coefficient and IoU score.

The generated masks are essentially random outputs with little meaningful overlap with the real masks. In other words, the Vanilla GAN has barely learned any meaningful medical mask structures.

## DCGAN GAN for Brain Tumor Segmentation

### Step 1: Build DCGAN
"""

# DCGAN Generator
def build_dcgan_generator(latent_dim):
    model = tf.keras.Sequential([
        layers.Dense(60 * 60 * 256, input_dim=latent_dim),
        layers.Reshape((60, 60, 256)),
        layers.BatchNormalization(),
        layers.ReLU(),

        layers.Conv2DTranspose(128, 4, strides=2, padding='same'),  # 120x120
        layers.BatchNormalization(),
        layers.ReLU(),

        layers.Conv2DTranspose(64, 4, strides=2, padding='same'),   # 240x240
        layers.BatchNormalization(),
        layers.ReLU(),

        layers.Conv2D(1, kernel_size=3, padding='same', activation='sigmoid')  # Final Output 240x240
    ], name="DCGAN_Generator")
    return model

# DCGAN Discriminator
def build_dcgan_discriminator():
    model = tf.keras.Sequential([
        layers.Conv2D(64, 4, strides=2, padding='same', input_shape=(240, 240, 1)),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(128, 4, strides=2, padding='same'),
        layers.BatchNormalization(),
        layers.LeakyReLU(alpha=0.2),
        layers.Conv2D(256, 4, strides=2, padding='same'),
        layers.BatchNormalization(),
        layers.LeakyReLU(alpha=0.2),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ], name="DCGAN_Discriminator")
    return model

"""### Step 2: Training Procedure for DCGAN"""

# Setup
latent_dim_dcgan = 100
dcgan_generator = build_dcgan_generator(latent_dim_dcgan)
dcgan_discriminator = build_dcgan_discriminator()

g_optimizer_dcgan = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
d_optimizer_dcgan = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)

@tf.function
def train_step_dcgan(real_masks):
    batch_size = tf.shape(real_masks)[0]
    real_labels = tf.ones((batch_size, 1))
    fake_labels = tf.zeros((batch_size, 1))

    # Train Discriminator
    with tf.GradientTape() as tape:
        noise = tf.random.normal((batch_size, latent_dim_dcgan))
        generated_masks = dcgan_generator(noise, training=True)

        real_output = dcgan_discriminator(real_masks, training=True)
        fake_output = dcgan_discriminator(generated_masks, training=True)

        d_loss_real = cross_entropy(real_labels, real_output)
        d_loss_fake = cross_entropy(fake_labels, fake_output)
        d_loss = (d_loss_real + d_loss_fake) / 2

    gradients_of_discriminator = tape.gradient(d_loss, dcgan_discriminator.trainable_variables)
    d_optimizer_dcgan.apply_gradients(zip(gradients_of_discriminator, dcgan_discriminator.trainable_variables))

    # Train Generator
    with tf.GradientTape() as tape:
        noise = tf.random.normal((batch_size, latent_dim_dcgan))
        generated_masks = dcgan_generator(noise, training=True)
        fake_output = dcgan_discriminator(generated_masks, training=True)

        g_loss = cross_entropy(real_labels, fake_output)

    gradients_of_generator = tape.gradient(g_loss, dcgan_generator.trainable_variables)
    g_optimizer_dcgan.apply_gradients(zip(gradients_of_generator, dcgan_generator.trainable_variables))

    return d_loss, g_loss

"""### Step 3: Training DCGAN"""

EPOCHS_DCGAN = 50

for epoch in range(EPOCHS_DCGAN):
    print(f"DCGAN Epoch {epoch+1}/{EPOCHS_DCGAN}")
    for real_masks in dataset:
        d_loss, g_loss = train_step_dcgan(real_masks)

    print(f"Discriminator Loss: {d_loss.numpy():.4f}, Generator Loss: {g_loss.numpy():.4f}")

"""### Step 4: Generate and visualize the results of the DCGAN"""

# Generate new predicted Mask
n_generate = 5
random_latent_vectors = tf.random.normal(shape=(n_generate, latent_dim_dcgan))
generated_masks_dcgan = dcgan_generator(random_latent_vectors)

# Visualization
fig, axs = plt.subplots(1, n_generate, figsize=(20, 5))

for i in range(n_generate):
    axs[i].imshow(generated_masks_dcgan[i, :, :, 0], cmap='gray', vmin=0, vmax=1)
    axs[i].axis('off')
    axs[i].set_title(f'DCGAN Generated Mask #{i+1}')

plt.tight_layout()
plt.show()

"""### Evaluation (Dice / IoU)"""

# Select real masks for evaluation
test_mask = mask_slices[:n_generate]

# The generated outputs are floats; binarize them
generated_masks_bin_dcgan = (generated_masks_dcgan.numpy() > 0.5).astype(np.float32)

# Calculate Dice and IoU
dice_dcgan = dice_coefficient(test_mask, generated_masks_bin_dcgan)
iou_dcgan = iou_score(test_mask, generated_masks_bin_dcgan)

print(f"DCGAN Dice Coefficient: {dice_dcgan.numpy():.4f}")
print(f"DCGAN IoU Score: {iou_dcgan.numpy():.4f}")

